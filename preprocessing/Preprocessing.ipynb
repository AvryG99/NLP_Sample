{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01-Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first NLP exercise is about preprocessing.\n",
    "\n",
    "You will practice preprocessing using NLTK on raw data. \n",
    "This is the first step in most of the NLP projects, so you have to master it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will play with the *coldplay.csv* dataset, containing all the songs and lyrics of Coldplay."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you know, the first step is to import some libraries. So import *nltk* as well as all the libraries you will need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Avry\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Avry\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Avry\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Avry\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    }
   ],
   "source": [
    "# Import NLTK and all the needed libraries\n",
    "import nltk\n",
    "nltk.download('punkt') #Run this line one time to get the resource\n",
    "nltk.download('stopwords') #Run this line one time to get the resource\n",
    "nltk.download('wordnet') #Run this line one time to get the resource\n",
    "nltk.download('averaged_perceptron_tagger') #Run this line one time to get the resource\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load now the dataset using pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Artist</th>\n",
       "      <th>Song</th>\n",
       "      <th>Link</th>\n",
       "      <th>Lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Coldplay</td>\n",
       "      <td>Another's Arms</td>\n",
       "      <td>/c/coldplay/anothers+arms_21079526.html</td>\n",
       "      <td>Late night watching tv  \\nUsed to be you here ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Coldplay</td>\n",
       "      <td>Bigger Stronger</td>\n",
       "      <td>/c/coldplay/bigger+stronger_20032648.html</td>\n",
       "      <td>I want to be bigger stronger drive a faster ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Coldplay</td>\n",
       "      <td>Daylight</td>\n",
       "      <td>/c/coldplay/daylight_20032625.html</td>\n",
       "      <td>To my surprise, and my delight  \\nI saw sunris...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Coldplay</td>\n",
       "      <td>Everglow</td>\n",
       "      <td>/c/coldplay/everglow_21104546.html</td>\n",
       "      <td>Oh, they say people come  \\nThey say people go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Coldplay</td>\n",
       "      <td>Every Teardrop Is A Waterfall</td>\n",
       "      <td>/c/coldplay/every+teardrop+is+a+waterfall_2091...</td>\n",
       "      <td>I turn the music up, I got my records on  \\nI ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Coldplay</td>\n",
       "      <td>Everything's Not Lost</td>\n",
       "      <td>/c/coldplay/everythings+not+lost_20032638.html</td>\n",
       "      <td>When I'm counting up my demons  \\nSaw there wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Coldplay</td>\n",
       "      <td>Fix You</td>\n",
       "      <td>/c/coldplay/fix+you_10069035.html</td>\n",
       "      <td>When you try your best but you don't succeed  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Coldplay</td>\n",
       "      <td>For You</td>\n",
       "      <td>/c/coldplay/for+you_20032655.html</td>\n",
       "      <td>If you're lost and feel alone  \\nCircumnavigat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Coldplay</td>\n",
       "      <td>Fun</td>\n",
       "      <td>/c/coldplay/fun_21104545.html</td>\n",
       "      <td>I know it's over before she says  \\nI know the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Coldplay</td>\n",
       "      <td>Ghost Story</td>\n",
       "      <td>/c/coldplay/ghost+story_21083666.html</td>\n",
       "      <td>Maybe I'm just a ghost  \\nDisappear when anybo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Artist                           Song  \\\n",
       "0  Coldplay                 Another's Arms   \n",
       "1  Coldplay                Bigger Stronger   \n",
       "2  Coldplay                       Daylight   \n",
       "3  Coldplay                       Everglow   \n",
       "4  Coldplay  Every Teardrop Is A Waterfall   \n",
       "5  Coldplay          Everything's Not Lost   \n",
       "6  Coldplay                        Fix You   \n",
       "7  Coldplay                        For You   \n",
       "8  Coldplay                            Fun   \n",
       "9  Coldplay                    Ghost Story   \n",
       "\n",
       "                                                Link  \\\n",
       "0            /c/coldplay/anothers+arms_21079526.html   \n",
       "1          /c/coldplay/bigger+stronger_20032648.html   \n",
       "2                 /c/coldplay/daylight_20032625.html   \n",
       "3                 /c/coldplay/everglow_21104546.html   \n",
       "4  /c/coldplay/every+teardrop+is+a+waterfall_2091...   \n",
       "5     /c/coldplay/everythings+not+lost_20032638.html   \n",
       "6                  /c/coldplay/fix+you_10069035.html   \n",
       "7                  /c/coldplay/for+you_20032655.html   \n",
       "8                      /c/coldplay/fun_21104545.html   \n",
       "9              /c/coldplay/ghost+story_21083666.html   \n",
       "\n",
       "                                              Lyrics  \n",
       "0  Late night watching tv  \\nUsed to be you here ...  \n",
       "1  I want to be bigger stronger drive a faster ca...  \n",
       "2  To my surprise, and my delight  \\nI saw sunris...  \n",
       "3  Oh, they say people come  \\nThey say people go...  \n",
       "4  I turn the music up, I got my records on  \\nI ...  \n",
       "5  When I'm counting up my demons  \\nSaw there wa...  \n",
       "6  When you try your best but you don't succeed  ...  \n",
       "7  If you're lost and feel alone  \\nCircumnavigat...  \n",
       "8  I know it's over before she says  \\nI know the...  \n",
       "9  Maybe I'm just a ghost  \\nDisappear when anybo...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Load the dataset in coldplay.csv\n",
    "df = pd.read_csv('coldplay.csv')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, check the dataset, play with it a bit: what are the columns? How many lines? Is there missing data?..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Overview:\n",
      "\n",
      "Number of Columns: 4\n",
      "Column Names: Artist, Song, Link, Lyrics\n",
      "Total Rows: 120\n",
      "\n",
      "Missing Data per Column:\n",
      "Artist    0\n",
      "Song      0\n",
      "Link      0\n",
      "Lyrics    0\n",
      "dtype: int64\n",
      "\n",
      "Number of Duplicate Rows: 0\n",
      "\n",
      "Data Types of Each Column:\n",
      "Artist    object\n",
      "Song      object\n",
      "Link      object\n",
      "Lyrics    object\n",
      "dtype: object\n",
      "\n",
      "Summary Statistics:\n",
      "          Artist            Song                                     Link  \\\n",
      "count        120             120                                      120   \n",
      "unique         1             120                                      120   \n",
      "top     Coldplay  Another's Arms  /c/coldplay/anothers+arms_21079526.html   \n",
      "freq         120               1                                        1   \n",
      "\n",
      "                                                   Lyrics  \n",
      "count                                                 120  \n",
      "unique                                                120  \n",
      "top     Late night watching tv  \\nUsed to be you here ...  \n",
      "freq                                                    1  \n",
      "\n",
      "Potential Outliers Detected:\n",
      "\n",
      "Memory Usage of DataFrame:\n",
      "Index        128\n",
      "Artist      7800\n",
      "Song        8484\n",
      "Link       11582\n",
      "Lyrics    121688\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# TODO: Explore the data# 1. Number of columns\n",
    "num_columns = df.shape[1]\n",
    "\n",
    "# 2. Column names\n",
    "column_names = df.columns.tolist()\n",
    "\n",
    "# 3. Total rows\n",
    "total_rows = df.shape[0]\n",
    "\n",
    "# 4. Check for missing data in each column\n",
    "missing_data = df.isnull().sum()\n",
    "\n",
    "# 5. Check for duplicate rows in the DataFrame\n",
    "duplicate_data = df.duplicated().sum()\n",
    "\n",
    "# 6. Data type of each column\n",
    "column_types = df.dtypes\n",
    "\n",
    "# Additional Checks\n",
    "\n",
    "# 7. Summary statistics\n",
    "summary_stats = df.describe(include='all')\n",
    "\n",
    "\n",
    "# 11. Outlier detection using IQR method\n",
    "outliers = {}\n",
    "for col in df.select_dtypes(include=['float64', 'int64']).columns:\n",
    "    Q1 = df[col].quantile(0.25)\n",
    "    Q3 = df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    outliers[col] = df[(df[col] < (Q1 - 1.5 * IQR)) | (df[col] > (Q3 + 1.5 * IQR))]\n",
    "\n",
    "# 12. Memory usage\n",
    "memory_usage = df.memory_usage(deep=True)\n",
    "\n",
    "# Display the results in a professional format\n",
    "print(f\"Dataset Overview:\\n\")\n",
    "print(f\"Number of Columns: {num_columns}\")\n",
    "print(f\"Column Names: {', '.join(column_names)}\")\n",
    "print(f\"Total Rows: {total_rows}\\n\")\n",
    "\n",
    "print(\"Missing Data per Column:\")\n",
    "print(missing_data)\n",
    "print(f\"\\nNumber of Duplicate Rows: {duplicate_data}\\n\")\n",
    "\n",
    "print(\"Data Types of Each Column:\")\n",
    "print(column_types)\n",
    "print(\"\\nSummary Statistics:\")\n",
    "print(summary_stats)\n",
    "\n",
    "print(\"\\nPotential Outliers Detected:\")\n",
    "for col, outlier_data in outliers.items():\n",
    "    print(f\"\\nColumn: {col}\")\n",
    "    print(outlier_data)\n",
    "\n",
    "print(\"\\nMemory Usage of DataFrame:\")\n",
    "print(memory_usage)\n",
    "\n",
    "# Data Distribution Visualization\n",
    "for col in df.select_dtypes(include=['float64', 'int64']).columns:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(df[col], bins=30, kde=True)\n",
    "    plt.title(f'Distribution of {col}')\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now select the song 'Every Teardrop Is A Waterfall' and save the Lyrics text into a variable. Print the output of this variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I turn the music up, I got my records on  \n",
      "I shut the world outside until the lights come on  \n",
      "Maybe the streets alight, maybe the trees are gone  \n",
      "I feel my heart start beating to my favourite song  \n",
      "  \n",
      "And all the kids they dance, all the kids all night  \n",
      "Until Monday morning feels another life  \n",
      "I turn the music up  \n",
      "I'm on a roll this time  \n",
      "And heaven is in sight  \n",
      "  \n",
      "I turn the music up, I got my records on  \n",
      "From underneath the rubble sing a rebel song  \n",
      "Don't want to see another generation drop  \n",
      "I'd rather be a comma than a full stop  \n",
      "  \n",
      "Maybe I'm in the black, maybe I'm on my knees  \n",
      "Maybe I'm in the gap between the two trapezes  \n",
      "But my heart is beating and my pulses start  \n",
      "Cathedrals in my heart  \n",
      "  \n",
      "As we saw oh this light I swear you, emerge blinking into  \n",
      "To tell me it's alright  \n",
      "As we soar walls, every siren is a symphony  \n",
      "And every tear's a waterfall  \n",
      "Is a waterfall  \n",
      "Oh  \n",
      "Is a waterfall  \n",
      "Oh oh oh  \n",
      "Is a is a waterfall  \n",
      "Every tear  \n",
      "Is a waterfall  \n",
      "Oh oh oh  \n",
      "  \n",
      "So you can hurt, hurt me bad  \n",
      "But still I'll raise the flag  \n",
      "  \n",
      "Oh  \n",
      "It was a wa wa wa wa wa-aterfall  \n",
      "A wa wa wa wa wa-aterfall  \n",
      "  \n",
      "Every tear  \n",
      "Every tear  \n",
      "Every teardrop is a waterfall  \n",
      "  \n",
      "Every tear  \n",
      "Every tear  \n",
      "Every teardrop is a waterfall  \n",
      "  \n",
      "Every tear  \n",
      "Every tear  \n",
      "Every teardrop is a waterfall\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO: Select the song 'Every Teardrop Is A Waterfall'\n",
    "lyrics_text = df[df['Song'].apply(lambda x: x == 'Every Teardrop Is A Waterfall')]['Lyrics'].values[0]\n",
    "\n",
    "print(lyrics_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, there is some preprocessing needed here. So let's do it! What is usually the first step?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenization, yes. So do tokenization on the lyrics of Every Teardrop Is A Waterfall.\n",
    "\n",
    "So you may have to import the needed library from NLTK if you did not yet.\n",
    "\n",
    "Be careful, the output you have from your pandas dataframe may not have the right type, so manipulate it wisely to get a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " 'turn',\n",
       " 'the',\n",
       " 'music',\n",
       " 'up',\n",
       " ',',\n",
       " 'I',\n",
       " 'got',\n",
       " 'my',\n",
       " 'records',\n",
       " 'on',\n",
       " 'I',\n",
       " 'shut',\n",
       " 'the',\n",
       " 'world',\n",
       " 'outside',\n",
       " 'until',\n",
       " 'the',\n",
       " 'lights',\n",
       " 'come',\n",
       " 'on',\n",
       " 'Maybe',\n",
       " 'the',\n",
       " 'streets',\n",
       " 'alight',\n",
       " ',',\n",
       " 'maybe',\n",
       " 'the',\n",
       " 'trees',\n",
       " 'are',\n",
       " 'gone',\n",
       " 'I',\n",
       " 'feel',\n",
       " 'my',\n",
       " 'heart',\n",
       " 'start',\n",
       " 'beating',\n",
       " 'to',\n",
       " 'my',\n",
       " 'favourite',\n",
       " 'song',\n",
       " 'And',\n",
       " 'all',\n",
       " 'the',\n",
       " 'kids',\n",
       " 'they',\n",
       " 'dance',\n",
       " ',',\n",
       " 'all',\n",
       " 'the',\n",
       " 'kids',\n",
       " 'all',\n",
       " 'night',\n",
       " 'Until',\n",
       " 'Monday',\n",
       " 'morning',\n",
       " 'feels',\n",
       " 'another',\n",
       " 'life',\n",
       " 'I',\n",
       " 'turn',\n",
       " 'the',\n",
       " 'music',\n",
       " 'up',\n",
       " 'I',\n",
       " \"'m\",\n",
       " 'on',\n",
       " 'a',\n",
       " 'roll',\n",
       " 'this',\n",
       " 'time',\n",
       " 'And',\n",
       " 'heaven',\n",
       " 'is',\n",
       " 'in',\n",
       " 'sight',\n",
       " 'I',\n",
       " 'turn',\n",
       " 'the',\n",
       " 'music',\n",
       " 'up',\n",
       " ',',\n",
       " 'I',\n",
       " 'got',\n",
       " 'my',\n",
       " 'records',\n",
       " 'on',\n",
       " 'From',\n",
       " 'underneath',\n",
       " 'the',\n",
       " 'rubble',\n",
       " 'sing',\n",
       " 'a',\n",
       " 'rebel',\n",
       " 'song',\n",
       " 'Do',\n",
       " \"n't\",\n",
       " 'want',\n",
       " 'to',\n",
       " 'see',\n",
       " 'another',\n",
       " 'generation',\n",
       " 'drop',\n",
       " 'I',\n",
       " \"'d\",\n",
       " 'rather',\n",
       " 'be',\n",
       " 'a',\n",
       " 'comma',\n",
       " 'than',\n",
       " 'a',\n",
       " 'full',\n",
       " 'stop',\n",
       " 'Maybe',\n",
       " 'I',\n",
       " \"'m\",\n",
       " 'in',\n",
       " 'the',\n",
       " 'black',\n",
       " ',',\n",
       " 'maybe',\n",
       " 'I',\n",
       " \"'m\",\n",
       " 'on',\n",
       " 'my',\n",
       " 'knees',\n",
       " 'Maybe',\n",
       " 'I',\n",
       " \"'m\",\n",
       " 'in',\n",
       " 'the',\n",
       " 'gap',\n",
       " 'between',\n",
       " 'the',\n",
       " 'two',\n",
       " 'trapezes',\n",
       " 'But',\n",
       " 'my',\n",
       " 'heart',\n",
       " 'is',\n",
       " 'beating',\n",
       " 'and',\n",
       " 'my',\n",
       " 'pulses',\n",
       " 'start',\n",
       " 'Cathedrals',\n",
       " 'in',\n",
       " 'my',\n",
       " 'heart',\n",
       " 'As',\n",
       " 'we',\n",
       " 'saw',\n",
       " 'oh',\n",
       " 'this',\n",
       " 'light',\n",
       " 'I',\n",
       " 'swear',\n",
       " 'you',\n",
       " ',',\n",
       " 'emerge',\n",
       " 'blinking',\n",
       " 'into',\n",
       " 'To',\n",
       " 'tell',\n",
       " 'me',\n",
       " 'it',\n",
       " \"'s\",\n",
       " 'alright',\n",
       " 'As',\n",
       " 'we',\n",
       " 'soar',\n",
       " 'walls',\n",
       " ',',\n",
       " 'every',\n",
       " 'siren',\n",
       " 'is',\n",
       " 'a',\n",
       " 'symphony',\n",
       " 'And',\n",
       " 'every',\n",
       " 'tear',\n",
       " \"'s\",\n",
       " 'a',\n",
       " 'waterfall',\n",
       " 'Is',\n",
       " 'a',\n",
       " 'waterfall',\n",
       " 'Oh',\n",
       " 'Is',\n",
       " 'a',\n",
       " 'waterfall',\n",
       " 'Oh',\n",
       " 'oh',\n",
       " 'oh',\n",
       " 'Is',\n",
       " 'a',\n",
       " 'is',\n",
       " 'a',\n",
       " 'waterfall',\n",
       " 'Every',\n",
       " 'tear',\n",
       " 'Is',\n",
       " 'a',\n",
       " 'waterfall',\n",
       " 'Oh',\n",
       " 'oh',\n",
       " 'oh',\n",
       " 'So',\n",
       " 'you',\n",
       " 'can',\n",
       " 'hurt',\n",
       " ',',\n",
       " 'hurt',\n",
       " 'me',\n",
       " 'bad',\n",
       " 'But',\n",
       " 'still',\n",
       " 'I',\n",
       " \"'ll\",\n",
       " 'raise',\n",
       " 'the',\n",
       " 'flag',\n",
       " 'Oh',\n",
       " 'It',\n",
       " 'was',\n",
       " 'a',\n",
       " 'wa',\n",
       " 'wa',\n",
       " 'wa',\n",
       " 'wa',\n",
       " 'wa-aterfall',\n",
       " 'A',\n",
       " 'wa',\n",
       " 'wa',\n",
       " 'wa',\n",
       " 'wa',\n",
       " 'wa-aterfall',\n",
       " 'Every',\n",
       " 'tear',\n",
       " 'Every',\n",
       " 'tear',\n",
       " 'Every',\n",
       " 'teardrop',\n",
       " 'is',\n",
       " 'a',\n",
       " 'waterfall',\n",
       " 'Every',\n",
       " 'tear',\n",
       " 'Every',\n",
       " 'tear',\n",
       " 'Every',\n",
       " 'teardrop',\n",
       " 'is',\n",
       " 'a',\n",
       " 'waterfall',\n",
       " 'Every',\n",
       " 'tear',\n",
       " 'Every',\n",
       " 'tear',\n",
       " 'Every',\n",
       " 'teardrop',\n",
       " 'is',\n",
       " 'a',\n",
       " 'waterfall']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Tokenize the lyrics of the song and save the tokens into a variable and print it\n",
    "token = word_tokenize(lyrics_text)\n",
    "token  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It begins to look good. But still, we have the punctuation to remove, so let's do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " 'turn',\n",
       " 'the',\n",
       " 'music',\n",
       " 'up',\n",
       " 'I',\n",
       " 'got',\n",
       " 'my',\n",
       " 'records',\n",
       " 'on',\n",
       " 'I',\n",
       " 'shut',\n",
       " 'the',\n",
       " 'world',\n",
       " 'outside',\n",
       " 'until',\n",
       " 'the',\n",
       " 'lights',\n",
       " 'come',\n",
       " 'on',\n",
       " 'Maybe',\n",
       " 'the',\n",
       " 'streets',\n",
       " 'alight',\n",
       " 'maybe',\n",
       " 'the',\n",
       " 'trees',\n",
       " 'are',\n",
       " 'gone',\n",
       " 'I',\n",
       " 'feel',\n",
       " 'my',\n",
       " 'heart',\n",
       " 'start',\n",
       " 'beating',\n",
       " 'to',\n",
       " 'my',\n",
       " 'favourite',\n",
       " 'song',\n",
       " 'And',\n",
       " 'all',\n",
       " 'the',\n",
       " 'kids',\n",
       " 'they',\n",
       " 'dance',\n",
       " 'all',\n",
       " 'the',\n",
       " 'kids',\n",
       " 'all',\n",
       " 'night',\n",
       " 'Until',\n",
       " 'Monday',\n",
       " 'morning',\n",
       " 'feels',\n",
       " 'another',\n",
       " 'life',\n",
       " 'I',\n",
       " 'turn',\n",
       " 'the',\n",
       " 'music',\n",
       " 'up',\n",
       " 'Im',\n",
       " 'on',\n",
       " 'a',\n",
       " 'roll',\n",
       " 'this',\n",
       " 'time',\n",
       " 'And',\n",
       " 'heaven',\n",
       " 'is',\n",
       " 'in',\n",
       " 'sight',\n",
       " 'I',\n",
       " 'turn',\n",
       " 'the',\n",
       " 'music',\n",
       " 'up',\n",
       " 'I',\n",
       " 'got',\n",
       " 'my',\n",
       " 'records',\n",
       " 'on',\n",
       " 'From',\n",
       " 'underneath',\n",
       " 'the',\n",
       " 'rubble',\n",
       " 'sing',\n",
       " 'a',\n",
       " 'rebel',\n",
       " 'song',\n",
       " 'Dont',\n",
       " 'want',\n",
       " 'to',\n",
       " 'see',\n",
       " 'another',\n",
       " 'generation',\n",
       " 'drop',\n",
       " 'Id',\n",
       " 'rather',\n",
       " 'be',\n",
       " 'a',\n",
       " 'comma',\n",
       " 'than',\n",
       " 'a',\n",
       " 'full',\n",
       " 'stop',\n",
       " 'Maybe',\n",
       " 'Im',\n",
       " 'in',\n",
       " 'the',\n",
       " 'black',\n",
       " 'maybe',\n",
       " 'Im',\n",
       " 'on',\n",
       " 'my',\n",
       " 'knees',\n",
       " 'Maybe',\n",
       " 'Im',\n",
       " 'in',\n",
       " 'the',\n",
       " 'gap',\n",
       " 'between',\n",
       " 'the',\n",
       " 'two',\n",
       " 'trapezes',\n",
       " 'But',\n",
       " 'my',\n",
       " 'heart',\n",
       " 'is',\n",
       " 'beating',\n",
       " 'and',\n",
       " 'my',\n",
       " 'pulses',\n",
       " 'start',\n",
       " 'Cathedrals',\n",
       " 'in',\n",
       " 'my',\n",
       " 'heart',\n",
       " 'As',\n",
       " 'we',\n",
       " 'saw',\n",
       " 'oh',\n",
       " 'this',\n",
       " 'light',\n",
       " 'I',\n",
       " 'swear',\n",
       " 'you',\n",
       " 'emerge',\n",
       " 'blinking',\n",
       " 'into',\n",
       " 'To',\n",
       " 'tell',\n",
       " 'me',\n",
       " 'its',\n",
       " 'alright',\n",
       " 'As',\n",
       " 'we',\n",
       " 'soar',\n",
       " 'walls',\n",
       " 'every',\n",
       " 'siren',\n",
       " 'is',\n",
       " 'a',\n",
       " 'symphony',\n",
       " 'And',\n",
       " 'every',\n",
       " 'tears',\n",
       " 'a',\n",
       " 'waterfall',\n",
       " 'Is',\n",
       " 'a',\n",
       " 'waterfall',\n",
       " 'Oh',\n",
       " 'Is',\n",
       " 'a',\n",
       " 'waterfall',\n",
       " 'Oh',\n",
       " 'oh',\n",
       " 'oh',\n",
       " 'Is',\n",
       " 'a',\n",
       " 'is',\n",
       " 'a',\n",
       " 'waterfall',\n",
       " 'Every',\n",
       " 'tear',\n",
       " 'Is',\n",
       " 'a',\n",
       " 'waterfall',\n",
       " 'Oh',\n",
       " 'oh',\n",
       " 'oh',\n",
       " 'So',\n",
       " 'you',\n",
       " 'can',\n",
       " 'hurt',\n",
       " 'hurt',\n",
       " 'me',\n",
       " 'bad',\n",
       " 'But',\n",
       " 'still',\n",
       " 'Ill',\n",
       " 'raise',\n",
       " 'the',\n",
       " 'flag',\n",
       " 'Oh',\n",
       " 'It',\n",
       " 'was',\n",
       " 'a',\n",
       " 'wa',\n",
       " 'wa',\n",
       " 'wa',\n",
       " 'wa',\n",
       " 'waaterfall',\n",
       " 'A',\n",
       " 'wa',\n",
       " 'wa',\n",
       " 'wa',\n",
       " 'wa',\n",
       " 'waaterfall',\n",
       " 'Every',\n",
       " 'tear',\n",
       " 'Every',\n",
       " 'tear',\n",
       " 'Every',\n",
       " 'teardrop',\n",
       " 'is',\n",
       " 'a',\n",
       " 'waterfall',\n",
       " 'Every',\n",
       " 'tear',\n",
       " 'Every',\n",
       " 'tear',\n",
       " 'Every',\n",
       " 'teardrop',\n",
       " 'is',\n",
       " 'a',\n",
       " 'waterfall',\n",
       " 'Every',\n",
       " 'tear',\n",
       " 'Every',\n",
       " 'tear',\n",
       " 'Every',\n",
       " 'teardrop',\n",
       " 'is',\n",
       " 'a',\n",
       " 'waterfall']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Remove the punctuation, then save the result into a variable and print it\n",
    "remove_punctuation_text = lyrics_text.translate(str.maketrans('', '', string.punctuation))\n",
    "removed_punctuation_token = word_tokenize(remove_punctuation_text)\n",
    "removed_punctuation_token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now remove the stop words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Avry\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    " \n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'his', \"don't\", 'yourself', 'll', 'as', 'of', 'only', 'your', 'we', 'yours', 'they', 'these', \"haven't\", 'off', 'have', 'before', 'after', 'down', 'about', 'mustn', 'no', 'from', 'should', \"she's\", 'doesn', 'i', \"mightn't\", \"aren't\", 'him', 'ain', 'doing', 'into', 'such', 'when', 'isn', 'all', \"you'd\", 'itself', \"hadn't\", 'and', 'very', 'between', 'couldn', 'been', 'but', 'if', 'because', 'too', 'few', 'did', 'be', 'in', 'can', \"won't\", 'nor', 'so', 'further', \"couldn't\", 'each', \"that'll\", 'on', \"shouldn't\", \"doesn't\", \"wouldn't\", 'any', 'ma', 'above', 'the', 're', 'or', 'it', 'where', 'being', 'through', \"didn't\", 'won', 'hasn', 'myself', 'o', \"weren't\", 'am', 'herself', \"needn't\", 'some', 'ourselves', 'for', 'an', 'more', 'don', 'below', 'needn', 'their', 'hers', 'over', \"hasn't\", 'will', 'he', 'haven', 'she', 'again', 'now', \"shan't\", 'what', 'a', 'this', 'under', 'both', 'm', \"you'll\", 'against', 'out', 'how', 'whom', 'didn', 'had', 'my', 'to', \"you're\", 'do', 'hadn', \"you've\", 'which', 'them', \"wasn't\", 'than', 'were', 'during', 'other', 'd', 'until', 'same', 'by', 'y', \"it's\", 'here', 'are', 'does', 'with', 'you', 'who', 't', 'just', 'once', 'its', 'shouldn', 'her', 'at', 'most', 've', 'me', 'not', \"should've\", 'ours', 'while', \"mustn't\", \"isn't\", 'having', 'weren', 'mightn', 'was', 'yourselves', 'then', 'has', 'wasn', 'those', 'why', 'there', 'himself', 'that', 'up', 'aren', 'is', 'themselves', 'our', 'own', 's', 'shan', 'theirs', 'wouldn'}\n"
     ]
    }
   ],
   "source": [
    "# TODO: remove the stop words using NLTK. Then put the result into a variable and print it\n",
    "stop_words = set(stopwords.words('english'))\n",
    "print(stop_words)\n",
    "removed_stopwords_lyrics = [w for w in removed_punctuation_token if not w.lower() in stop_words]\n",
    "\n",
    "# removed_stopwords_lyrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay we begin to have much less words in our song, right?\n",
    "\n",
    "Next step is lemmatization. But we had an issue in the lectures, you remember? Let's learn how to do it properly now.\n",
    "\n",
    "First let's try to do it naively. Import the WordNetLemmatizer and perform lemmatization with default options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    " \n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "# TODO: Perform lemmatization using WordNetLemmatizer on our tokens\n",
    "lemmatized_origin = []\n",
    "for w in token:\n",
    "    lemmatized_origin.append(lemmatizer.lemmatize(w))\n",
    "\n",
    "#Check if the tokens are lemmatized yet or not.\n",
    "#Return false if the tokens are lemmatized\n",
    "print(lemmatized_origin == token)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, it worked well on nouns (plural words are now singular for example).\n",
    "\n",
    "But verbs are not OK: we would 'is' to become 'be' for example.\n",
    "\n",
    "To do that, we need to do POS-tagging. So let's do this now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "POS-tagging means Part of speech tagging: basically it will classify words into categories: like verbs, nouns, advers and so on...\n",
    "\n",
    "In order to do that, we will use NLTK and the function *pos_tag*. You have to do it on the step before lemmatization, so use your variable containing all the tokens without punctuation and without stop words.\n",
    "\n",
    "Hint: you can check on the internet how the *pos_tag* function works [here](https://www.nltk.org/book/ch05.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: use the function pos_tag of NLTK to perform POS-tagging and print the result\n",
    "'''\n",
    "Notice that the removed_stopwords_lyrics is containing the list of words\n",
    "that are removed both stopwords and punctuations\n",
    "'''\n",
    "pos_tags = pos_tag(removed_stopwords_lyrics)\n",
    "lemmatizer = WordNetLemmatizer()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, it does not return values like 'a', 'n', 'v' or 'r' as the WordNet lemmatizer is expecting...\n",
    "\n",
    "So we have to convert the values from the NLTK POS-tagging to put them into the WordNet Lemmatizer. This is done in the function *get_wordnet_pos* written below. Try to understand it, and then we will reuse it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatize tokens with POS tagging\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return nltk.corpus.wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return nltk.corpus.wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return nltk.corpus.wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return nltk.corpus.wordnet.ADV\n",
    "    else:\n",
    "        return nltk.corpus.wordnet.NOUN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now you have all we need to perform properly the lemmatization.\n",
    "\n",
    "So you have to use the following to do so:\n",
    "* your tags from the POS-tagging performed\n",
    "* the function *get_wordnet_pos*\n",
    "* the *WordNetLemmatizer*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['turn',\n",
       " 'music',\n",
       " 'get',\n",
       " 'record',\n",
       " 'shut',\n",
       " 'world',\n",
       " 'outside',\n",
       " 'light',\n",
       " 'come',\n",
       " 'Maybe',\n",
       " 'street',\n",
       " 'alight',\n",
       " 'maybe',\n",
       " 'tree',\n",
       " 'go',\n",
       " 'feel',\n",
       " 'heart',\n",
       " 'start',\n",
       " 'beat',\n",
       " 'favourite',\n",
       " 'song',\n",
       " 'kid',\n",
       " 'dance',\n",
       " 'kid',\n",
       " 'night',\n",
       " 'Monday',\n",
       " 'morning',\n",
       " 'feel',\n",
       " 'another',\n",
       " 'life',\n",
       " 'turn',\n",
       " 'music',\n",
       " 'Im',\n",
       " 'roll',\n",
       " 'time',\n",
       " 'heaven',\n",
       " 'sight',\n",
       " 'turn',\n",
       " 'music',\n",
       " 'get',\n",
       " 'record',\n",
       " 'underneath',\n",
       " 'rubble',\n",
       " 'sing',\n",
       " 'rebel',\n",
       " 'song',\n",
       " 'Dont',\n",
       " 'want',\n",
       " 'see',\n",
       " 'another',\n",
       " 'generation',\n",
       " 'drop',\n",
       " 'Id',\n",
       " 'rather',\n",
       " 'comma',\n",
       " 'full',\n",
       " 'stop',\n",
       " 'Maybe',\n",
       " 'Im',\n",
       " 'black',\n",
       " 'maybe',\n",
       " 'Im',\n",
       " 'knee',\n",
       " 'Maybe',\n",
       " 'Im',\n",
       " 'gap',\n",
       " 'two',\n",
       " 'trapezes',\n",
       " 'heart',\n",
       " 'beating',\n",
       " 'pulse',\n",
       " 'start',\n",
       " 'Cathedrals',\n",
       " 'heart',\n",
       " 'saw',\n",
       " 'oh',\n",
       " 'light',\n",
       " 'swear',\n",
       " 'emerge',\n",
       " 'blink',\n",
       " 'tell',\n",
       " 'alright',\n",
       " 'soar',\n",
       " 'wall',\n",
       " 'every',\n",
       " 'siren',\n",
       " 'symphony',\n",
       " 'every',\n",
       " 'tear',\n",
       " 'waterfall',\n",
       " 'waterfall',\n",
       " 'Oh',\n",
       " 'waterfall',\n",
       " 'Oh',\n",
       " 'oh',\n",
       " 'oh',\n",
       " 'waterfall',\n",
       " 'Every',\n",
       " 'tear',\n",
       " 'waterfall',\n",
       " 'Oh',\n",
       " 'oh',\n",
       " 'oh',\n",
       " 'hurt',\n",
       " 'hurt',\n",
       " 'bad',\n",
       " 'still',\n",
       " 'Ill',\n",
       " 'raise',\n",
       " 'flag',\n",
       " 'Oh',\n",
       " 'wa',\n",
       " 'wa',\n",
       " 'wa',\n",
       " 'wa',\n",
       " 'waaterfall',\n",
       " 'wa',\n",
       " 'wa',\n",
       " 'wa',\n",
       " 'wa',\n",
       " 'waaterfall',\n",
       " 'Every',\n",
       " 'tear',\n",
       " 'Every',\n",
       " 'tear',\n",
       " 'Every',\n",
       " 'teardrop',\n",
       " 'waterfall',\n",
       " 'Every',\n",
       " 'tear',\n",
       " 'Every',\n",
       " 'tear',\n",
       " 'Every',\n",
       " 'teardrop',\n",
       " 'waterfall',\n",
       " 'Every',\n",
       " 'tear',\n",
       " 'Every',\n",
       " 'tear',\n",
       " 'Every',\n",
       " 'teardrop',\n",
       " 'waterfall']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Perform the lemmatization properly\n",
    "lemmatized_tokens = [lemmatizer.lemmatize(word, get_wordnet_pos(tag)) for word, tag in pos_tags]\n",
    "\n",
    "# Check if the tokens are lemmatized. False if lemmatized\n",
    "are_tokens_lemmatized = lemmatized_tokens == token\n",
    "lemmatized_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you think?\n",
    "\n",
    "Still not perfect, but it's the best we can do for now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can try stemming, with the help of the lecture, and see the differences compared to the lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['turn',\n",
       " 'music',\n",
       " 'got',\n",
       " 'record',\n",
       " 'shut',\n",
       " 'world',\n",
       " 'outsid',\n",
       " 'light',\n",
       " 'come',\n",
       " 'mayb',\n",
       " 'street',\n",
       " 'alight',\n",
       " 'mayb',\n",
       " 'tree',\n",
       " 'gone',\n",
       " 'feel',\n",
       " 'heart',\n",
       " 'start',\n",
       " 'beat',\n",
       " 'favourit',\n",
       " 'song',\n",
       " 'kid',\n",
       " 'danc',\n",
       " 'kid',\n",
       " 'night',\n",
       " 'monday',\n",
       " 'morn',\n",
       " 'feel',\n",
       " 'anoth',\n",
       " 'life',\n",
       " 'turn',\n",
       " 'music',\n",
       " 'im',\n",
       " 'roll',\n",
       " 'time',\n",
       " 'heaven',\n",
       " 'sight',\n",
       " 'turn',\n",
       " 'music',\n",
       " 'got',\n",
       " 'record',\n",
       " 'underneath',\n",
       " 'rubbl',\n",
       " 'sing',\n",
       " 'rebel',\n",
       " 'song',\n",
       " 'dont',\n",
       " 'want',\n",
       " 'see',\n",
       " 'anoth',\n",
       " 'gener',\n",
       " 'drop',\n",
       " 'id',\n",
       " 'rather',\n",
       " 'comma',\n",
       " 'full',\n",
       " 'stop',\n",
       " 'mayb',\n",
       " 'im',\n",
       " 'black',\n",
       " 'mayb',\n",
       " 'im',\n",
       " 'knee',\n",
       " 'mayb',\n",
       " 'im',\n",
       " 'gap',\n",
       " 'two',\n",
       " 'trapez',\n",
       " 'heart',\n",
       " 'beat',\n",
       " 'puls',\n",
       " 'start',\n",
       " 'cathedr',\n",
       " 'heart',\n",
       " 'saw',\n",
       " 'oh',\n",
       " 'light',\n",
       " 'swear',\n",
       " 'emerg',\n",
       " 'blink',\n",
       " 'tell',\n",
       " 'alright',\n",
       " 'soar',\n",
       " 'wall',\n",
       " 'everi',\n",
       " 'siren',\n",
       " 'symphoni',\n",
       " 'everi',\n",
       " 'tear',\n",
       " 'waterfal',\n",
       " 'waterfal',\n",
       " 'oh',\n",
       " 'waterfal',\n",
       " 'oh',\n",
       " 'oh',\n",
       " 'oh',\n",
       " 'waterfal',\n",
       " 'everi',\n",
       " 'tear',\n",
       " 'waterfal',\n",
       " 'oh',\n",
       " 'oh',\n",
       " 'oh',\n",
       " 'hurt',\n",
       " 'hurt',\n",
       " 'bad',\n",
       " 'still',\n",
       " 'ill',\n",
       " 'rais',\n",
       " 'flag',\n",
       " 'oh',\n",
       " 'wa',\n",
       " 'wa',\n",
       " 'wa',\n",
       " 'wa',\n",
       " 'waaterfal',\n",
       " 'wa',\n",
       " 'wa',\n",
       " 'wa',\n",
       " 'wa',\n",
       " 'waaterfal',\n",
       " 'everi',\n",
       " 'tear',\n",
       " 'everi',\n",
       " 'tear',\n",
       " 'everi',\n",
       " 'teardrop',\n",
       " 'waterfal',\n",
       " 'everi',\n",
       " 'tear',\n",
       " 'everi',\n",
       " 'tear',\n",
       " 'everi',\n",
       " 'teardrop',\n",
       " 'waterfal',\n",
       " 'everi',\n",
       " 'tear',\n",
       " 'everi',\n",
       " 'tear',\n",
       " 'everi',\n",
       " 'teardrop',\n",
       " 'waterfal']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Perform stemming\n",
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "stemmed = [stemmer.stem(word) for word in removed_stopwords_lyrics]\n",
    "stemmed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you see the difference? What would you use?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both stemming and lemmatizing are working on the same idea of return the words into their original form.\n",
    "But the result of stemming seems like it made some spelling mistakes in the result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "e13f56ca7dc4f574cb8c974a7b4bbe558c017ba4c5a83757e058a9f98049b048"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
